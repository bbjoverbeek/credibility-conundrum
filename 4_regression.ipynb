{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Experiments\n",
    "_Training regression models to see how well we can predict claimant reliablity, and what features contribute the most to the results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from util import gather_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gather_dataset('./data/claimant_data_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(\n",
    "    df: pd.DataFrame, train: int = 70, dev: int = 10, test: int = 20\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split the dataset into a train, dev, and test split using the specified percentages.\"\"\"\n",
    "\n",
    "    if (train + dev + test) != 100:\n",
    "        raise ValueError('The train, dev, and test splits must sum to 100.')\n",
    "\n",
    "    train_split, temp_split = train_test_split(\n",
    "        df, test_size=(dev + test) / 100, random_state=42\n",
    "    )\n",
    "\n",
    "    dev_split, test_split = train_test_split(\n",
    "        temp_split, test_size=test / (dev + test), random_state=42\n",
    "    )\n",
    "\n",
    "    return train_split, dev_split, test_split\n",
    "\n",
    "\n",
    "train_split, _, test_split = create_splits(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy regressor MSE: 1.676\n"
     ]
    }
   ],
   "source": [
    "# fit the baseline model\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "dummy_regressor.fit(train_split['source'], train_split['score']) # type: ignore\n",
    "\n",
    "# predict on the test set\n",
    "predictions = dummy_regressor.predict(test_split['source']) # type: ignore\n",
    "\n",
    "# get MSE\n",
    "mse = mean_squared_error(test_split['score'], predictions)\n",
    "\n",
    "print(f'Dummy regressor MSE: {mse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "Here we test different combinations between the following features:\n",
    "* claimant embeddings\n",
    "* claimant categories\n",
    "* publishers\n",
    "* publisher categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import combinations\n",
    "from typing import Literal, get_args\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "Feature = Literal['claimant_embeddings', 'claimant_embeddings_context', 'claimant_category', 'publisher', 'publisher_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_response_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source</th>\n",
       "      <th>reliability</th>\n",
       "      <th>Optional Comments:</th>\n",
       "      <th>batch_no</th>\n",
       "      <th>score</th>\n",
       "      <th>claimant_embeddings</th>\n",
       "      <th>claimant_embeddings_context</th>\n",
       "      <th>claimant_type_id</th>\n",
       "      <th>publisher_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>C6HPNPP7A7E9</td>\n",
       "      <td>3aabc46f-2715-456e-9d82-2e3814e871e8</td>\n",
       "      <td>2bf33773-a7f4-42a0-a1e1-e6dce2b2e243</td>\n",
       "      <td>LifeSiteNews_20170611T045238.conll.annot</td>\n",
       "      <td>5</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>LifeSiteNews</td>\n",
       "      <td>Priests throughout Kenya</td>\n",
       "      <td>3 - The source is potentially reliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.5763444900512695, -0.09419417381286621, 0....</td>\n",
       "      <td>[-0.4169674217700958, -0.5285131931304932, 0.1...</td>\n",
       "      <td>5</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11770</th>\n",
       "      <td>QAPRY4VGE6MY</td>\n",
       "      <td>e2efae9e-4093-40d3-8eef-2804ed02e6a9</td>\n",
       "      <td>6b594980-2e4d-4f00-a566-6b6961e27ecf</td>\n",
       "      <td>thinktwice-com_20170627T225319.conll.annot</td>\n",
       "      <td>137</td>\n",
       "      <td>1 2</td>\n",
       "      <td>www.thinktwice.com</td>\n",
       "      <td>The doctors</td>\n",
       "      <td>5 - The source is fully reliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.4354318380355835, -0.07199427485466003, 0....</td>\n",
       "      <td>[-0.06363115832209587, -0.6982768476009369, 0....</td>\n",
       "      <td>5</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>7R2NKCJQNXPP</td>\n",
       "      <td>c59835da-53fd-4666-9dcb-d26ec0f547a4</td>\n",
       "      <td>1aa59dc4-e15f-4336-9851-0cf7a494e469</td>\n",
       "      <td>LifeSiteNews_20170611T045238.conll.annot</td>\n",
       "      <td>5</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>LifeSiteNews</td>\n",
       "      <td>Priests throughout Kenya</td>\n",
       "      <td>4 - The source is somewhat reliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5763444900512695, -0.09419417381286621, 0....</td>\n",
       "      <td>[-0.4169674217700958, -0.5285131931304932, 0.1...</td>\n",
       "      <td>5</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Z6J69GNZYEXY</td>\n",
       "      <td>241a4178-4073-422f-ac00-a79204e15ffa</td>\n",
       "      <td>b195d4a9-4cb5-4465-839e-64555536f6f2</td>\n",
       "      <td>sharylattkisson-com_20171001T192931.conll.annot</td>\n",
       "      <td>79</td>\n",
       "      <td>4 5 6 7 8 9 10</td>\n",
       "      <td>sharylattkisson.com</td>\n",
       "      <td>her colleagues at the Institute of Medicine</td>\n",
       "      <td>3 - The source is potentially reliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.36997485160827637, -0.04534153640270233, 0...</td>\n",
       "      <td>[-0.03363962897232601, -0.25278040054919465, 0...</td>\n",
       "      <td>5</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>ATEZ9499929P</td>\n",
       "      <td>ef5fde58-e1d7-435a-b546-3ebb7b612427</td>\n",
       "      <td>974c25fe-66d8-449f-86e3-253213ec3855</td>\n",
       "      <td>International-Medical-Council-on-Vaccination_2...</td>\n",
       "      <td>61</td>\n",
       "      <td>1 2 3 4 5 6</td>\n",
       "      <td>International Medical Council on Vaccination</td>\n",
       "      <td>Vikari et al. ( 1979 .</td>\n",
       "      <td>5 - The source is fully reliable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.5054624080657959, -0.1212393119931221, 0.1...</td>\n",
       "      <td>[-0.7636523594458898, -0.20012776831087345, -0...</td>\n",
       "      <td>6</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          worker_id                               task_id  \\\n",
       "10069  C6HPNPP7A7E9  3aabc46f-2715-456e-9d82-2e3814e871e8   \n",
       "11770  QAPRY4VGE6MY  e2efae9e-4093-40d3-8eef-2804ed02e6a9   \n",
       "1414   7R2NKCJQNXPP  c59835da-53fd-4666-9dcb-d26ec0f547a4   \n",
       "499    Z6J69GNZYEXY  241a4178-4073-422f-ac00-a79204e15ffa   \n",
       "668    ATEZ9499929P  ef5fde58-e1d7-435a-b546-3ebb7b612427   \n",
       "\n",
       "                           task_response_id  \\\n",
       "10069  2bf33773-a7f4-42a0-a1e1-e6dce2b2e243   \n",
       "11770  6b594980-2e4d-4f00-a566-6b6961e27ecf   \n",
       "1414   1aa59dc4-e15f-4336-9851-0cf7a494e469   \n",
       "499    b195d4a9-4cb5-4465-839e-64555536f6f2   \n",
       "668    974c25fe-66d8-449f-86e3-253213ec3855   \n",
       "\n",
       "                                                 file_id  sentence  \\\n",
       "10069           LifeSiteNews_20170611T045238.conll.annot         5   \n",
       "11770         thinktwice-com_20170627T225319.conll.annot       137   \n",
       "1414            LifeSiteNews_20170611T045238.conll.annot         5   \n",
       "499      sharylattkisson-com_20171001T192931.conll.annot        79   \n",
       "668    International-Medical-Council-on-Vaccination_2...        61   \n",
       "\n",
       "            tokens_id                                     publisher  \\\n",
       "10069           1 2 3                                  LifeSiteNews   \n",
       "11770             1 2                            www.thinktwice.com   \n",
       "1414            1 2 3                                  LifeSiteNews   \n",
       "499    4 5 6 7 8 9 10                           sharylattkisson.com   \n",
       "668       1 2 3 4 5 6  International Medical Council on Vaccination   \n",
       "\n",
       "                                            source  \\\n",
       "10069                     Priests throughout Kenya   \n",
       "11770                                  The doctors   \n",
       "1414                      Priests throughout Kenya   \n",
       "499    her colleagues at the Institute of Medicine   \n",
       "668                         Vikari et al. ( 1979 .   \n",
       "\n",
       "                                  reliability Optional Comments:  batch_no  \\\n",
       "10069  3 - The source is potentially reliable                NaN         4   \n",
       "11770        5 - The source is fully reliable                NaN         2   \n",
       "1414      4 - The source is somewhat reliable                NaN         5   \n",
       "499    3 - The source is potentially reliable                NaN         1   \n",
       "668          5 - The source is fully reliable                NaN         5   \n",
       "\n",
       "       score                                claimant_embeddings  \\\n",
       "10069      3  [-0.5763444900512695, -0.09419417381286621, 0....   \n",
       "11770      5  [-0.4354318380355835, -0.07199427485466003, 0....   \n",
       "1414       4  [-0.5763444900512695, -0.09419417381286621, 0....   \n",
       "499        3  [-0.36997485160827637, -0.04534153640270233, 0...   \n",
       "668        5  [-0.5054624080657959, -0.1212393119931221, 0.1...   \n",
       "\n",
       "                             claimant_embeddings_context  claimant_type_id  \\\n",
       "10069  [-0.4169674217700958, -0.5285131931304932, 0.1...                 5   \n",
       "11770  [-0.06363115832209587, -0.6982768476009369, 0....                 5   \n",
       "1414   [-0.4169674217700958, -0.5285131931304932, 0.1...                 5   \n",
       "499    [-0.03363962897232601, -0.25278040054919465, 0...                 5   \n",
       "668    [-0.7636523594458898, -0.20012776831087345, -0...                 6   \n",
       "\n",
       "      publisher_category  \n",
       "10069    not established  \n",
       "11770    not established  \n",
       "1414     not established  \n",
       "499      not established  \n",
       "668      not established  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add all features to the df\n",
    "\n",
    "# claimant embeddings without context\n",
    "embeddings_df = pd.read_pickle('./data/claimant_embeddings_deberta-v3-large.pickle')\n",
    "df = df.merge(embeddings_df[['task_id', 'embeddings']], on='task_id')\n",
    "\n",
    "# claimant embeddings out of context\n",
    "df = df.merge(embeddings_df[['task_id', 'context_embeddings']], on='task_id')\n",
    "\n",
    "# claimant categories\n",
    "claimant_categories_df = pd.read_csv('./annotations/claimant_annotations.csv')\n",
    "claimant_categories_df['claimant_type_id'] = claimant_categories_df['ClaimantType'].apply(lambda type_: int(type_.lstrip()[0]))\n",
    "df = df.merge(claimant_categories_df[['task_id', 'claimant_type_id']], on='task_id')\n",
    "\n",
    "# publisher categories\n",
    "publisher_category_df = pd.read_csv('./annotations/publisher_annotations.csv')\n",
    "df = df.merge(publisher_category_df[['publisher', 'category']], on='publisher')\n",
    "\n",
    "# rename columns for clarity\n",
    "df.rename(columns={\n",
    "    'embeddings': 'claimant_embeddings', \n",
    "    'context_embeddings': 'claimant_embeddings_context',\n",
    "    'category': 'publisher_category'\n",
    "}, inplace=True)\n",
    "\n",
    "train_split, _, test_split = create_splits(df)\n",
    "\n",
    "train_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(\n",
    "        df: pd.DataFrame,\n",
    "        claimant_embeddings: bool = True,\n",
    "        claimant_embeddings_context: bool = False,\n",
    "        claimant_category_binarizer: LabelBinarizer|None = None,\n",
    "        publisher_binarizer: LabelBinarizer|None = None,\n",
    "        publisher_category_binarizer: LabelBinarizer|None = None,\n",
    "    ) -> list[list[float|int]]:\n",
    "    \"\"\"Uses columns to create a feature array for training the regression model\"\"\"\n",
    "\n",
    "    X = [[] for _ in range(len(df))]\n",
    "    for idx, (_, row) in enumerate(df.iterrows()):\n",
    "\n",
    "        # add word embeddings to the feature\n",
    "        if claimant_embeddings:\n",
    "            X[idx].extend(list(row['claimant_embeddings'])) # type: ignore\n",
    "\n",
    "        if claimant_embeddings_context:\n",
    "            X[idx].extend(list(row['claimant_embeddings_context'])) # type: ignore\n",
    "\n",
    "        if claimant_category_binarizer: # if a claimant category binarizer was passed, add as feature\n",
    "            X[idx].extend(claimant_category_binarizer.transform([row['claimant_type_id']])[0])\n",
    "\n",
    "        if publisher_binarizer: # if a publisher binarizer was passed, add as feature\n",
    "            X[idx].extend(publisher_binarizer.transform([row['publisher']])[0])\n",
    "\n",
    "        if publisher_category_binarizer: # if a publisher category binarizer was passed, add as feature\n",
    "            X[idx].extend(publisher_category_binarizer.transform([row['publisher_category']])[0])\n",
    "            \n",
    "        \n",
    "\n",
    "    return X\n",
    "\n",
    "# initialize label binarizers\n",
    "claimant_category_binarizer = LabelBinarizer().fit(df['claimant_type_id'])\n",
    "publisher_binarizer = LabelBinarizer().fit(df['publisher'])\n",
    "publisher_category_binarizer = LabelBinarizer().fit(df['publisher_category'])\n",
    "\n",
    "binarizers: dict[Feature, LabelBinarizer] = {'claimant_category': claimant_category_binarizer, 'publisher': publisher_binarizer, 'publisher_category': publisher_category_binarizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test experiment MSE: 1.135, and R2: 0.323\n"
     ]
    }
   ],
   "source": [
    "MSE = float\n",
    "RSQUARED = float\n",
    "\n",
    "def run_experiment(train_split: pd.DataFrame, test_split: pd.DataFrame, binarizers: dict[Feature, LabelBinarizer], features: tuple[Feature,...], model:LinearSVR|LinearRegression) -> tuple[MSE, RSQUARED]:\n",
    "    \"\"\"Extracts the correct features, trains a regression model, and returns the MSE on the test set\"\"\"\n",
    "\n",
    "    X_train = create_features(\n",
    "        train_split,\n",
    "        claimant_embeddings=True if 'claimant_embeddings' in features else False,\n",
    "        claimant_embeddings_context=True if 'claimant_embeddings_context' in features else False,\n",
    "        claimant_category_binarizer=binarizers['claimant_category'] if 'claimant_category' in features else None,\n",
    "        publisher_binarizer=binarizers['publisher'] if 'publisher' in features else None,\n",
    "        publisher_category_binarizer=binarizers['publisher_category'] if 'publisher_category' in features else None,\n",
    "    )\n",
    "    y_train = list(train_split['score'])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = create_features(\n",
    "        test_split,\n",
    "        claimant_embeddings=True if 'claimant_embeddings' in features else False,\n",
    "        claimant_embeddings_context=True if 'claimant_embeddings_context' in features else False,\n",
    "        claimant_category_binarizer=binarizers['claimant_category'] if 'claimant_category' in features else None,\n",
    "        publisher_binarizer=binarizers['publisher'] if 'publisher' in features else None,\n",
    "        publisher_category_binarizer=binarizers['publisher_category'] if 'publisher_category' in features else None,\n",
    "    )\n",
    "    y_test = list(test_split['score'])\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = model.score(X_test, y_test)\n",
    "\n",
    "    return mse, r2\n",
    "\n",
    "# code to test function definition\n",
    "model = LinearRegression()\n",
    "mse, r2 = run_experiment(train_split, test_split, binarizers, ('claimant_embeddings', 'publisher'), model)\n",
    "print(f'Test experiment MSE: {mse:.3f}, and R2: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiment for all combinations of features \n",
    "features = get_args(Feature)\n",
    "feature_combinations = tuple(combination for num in range(1, len(features) + 1) for combination in combinations(features, num))\n",
    "# remove occurances where both types of embeddings occur together\n",
    "feature_combinations = tuple(combination for combination in feature_combinations if not ('claimant_embeddings' in combination and 'claimant_embeddings_context' in combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimant_embeddings</th>\n",
       "      <th>claimant_embeddings_context</th>\n",
       "      <th>claimant_type_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publisher_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.3007359802722931, -0.060107577592134476, 0...</td>\n",
       "      <td>[0.21119636182601637, -0.3454102518287702, 0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>ThinkProgress</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.3007359802722931, -0.060107577592134476, 0...</td>\n",
       "      <td>[0.21119636182601637, -0.3454102518287702, 0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>ThinkProgress</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.5612852573394775, -0.03220456838607788, 0....</td>\n",
       "      <td>[0.17742657661437988, -0.19991786777973175, 0....</td>\n",
       "      <td>6</td>\n",
       "      <td>PublicHealth.org</td>\n",
       "      <td>established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.3007359802722931, -0.060107577592134476, 0...</td>\n",
       "      <td>[0.21119636182601637, -0.3454102518287702, 0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>ThinkProgress</td>\n",
       "      <td>not established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.5341578125953674, -0.10339929163455963, 0....</td>\n",
       "      <td>[-0.5530586391687393, 0.4381181299686432, 0.44...</td>\n",
       "      <td>2</td>\n",
       "      <td>National Vaccine Information Center (NVIC)</td>\n",
       "      <td>governmental/institutional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 claimant_embeddings  \\\n",
       "0  [-0.3007359802722931, -0.060107577592134476, 0...   \n",
       "1  [-0.3007359802722931, -0.060107577592134476, 0...   \n",
       "2  [-0.5612852573394775, -0.03220456838607788, 0....   \n",
       "3  [-0.3007359802722931, -0.060107577592134476, 0...   \n",
       "4  [-0.5341578125953674, -0.10339929163455963, 0....   \n",
       "\n",
       "                         claimant_embeddings_context  claimant_type_id  \\\n",
       "0  [0.21119636182601637, -0.3454102518287702, 0.0...                 2   \n",
       "1  [0.21119636182601637, -0.3454102518287702, 0.0...                 2   \n",
       "2  [0.17742657661437988, -0.19991786777973175, 0....                 6   \n",
       "3  [0.21119636182601637, -0.3454102518287702, 0.0...                 2   \n",
       "4  [-0.5530586391687393, 0.4381181299686432, 0.44...                 2   \n",
       "\n",
       "                                    publisher          publisher_category  \n",
       "0                               ThinkProgress             not established  \n",
       "1                               ThinkProgress             not established  \n",
       "2                            PublicHealth.org                 established  \n",
       "3                               ThinkProgress             not established  \n",
       "4  National Vaccine Information Center (NVIC)  governmental/institutional  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df[['claimant_embeddings', 'claimant_embeddings_context', 'claimant_type_id', 'publisher', 'publisher_category']]\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature                       VIF\n",
      "---------------------------------------------\n",
      "claimant_embeddings           None\n",
      "claimant_embeddings_context   None\n",
      "claimant_category             None\n",
      "publisher                     None\n",
      "publisher_category            None\n"
     ]
    }
   ],
   "source": [
    "# test for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "vif_scores = {feature: None for feature in features}\n",
    "\n",
    "# print([variance_inflation_factor(features_df.values, i) for i in range(len(features_df.columns))])\n",
    "\n",
    "print(f'{\"feature\":30}{\"VIF\"}')\n",
    "print('---'*15)\n",
    "for feature, vif_score in vif_scores.items():\n",
    "    print(f'{feature:30}{vif_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a51d0f9f912416a84dd52593f13e31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Linear Regression experiments:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claimant_embeddings & claimant_category & publisher_category____________________ MSE: 1.12956 R2: 0.32584\n",
      "claimant_embeddings & publisher_category________________________________________ MSE: 1.12979 R2: 0.32570\n",
      "claimant_embeddings & claimant_category & publisher_____________________________ MSE: 1.13462 R2: 0.32282\n",
      "claimant_embeddings & claimant_category & publisher & publisher_category________ MSE: 1.13462 R2: 0.32282\n",
      "claimant_embeddings & publisher_________________________________________________ MSE: 1.13469 R2: 0.32278\n",
      "claimant_embeddings & publisher & publisher_category____________________________ MSE: 1.13484 R2: 0.32269\n",
      "claimant_embeddings & claimant_category_________________________________________ MSE: 1.13520 R2: 0.32247\n",
      "claimant_embeddings_____________________________________________________________ MSE: 1.13643 R2: 0.32173\n",
      "claimant_embeddings_context & claimant_category_________________________________ MSE: 1.13904 R2: 0.32018\n",
      "claimant_embeddings_context_____________________________________________________ MSE: 1.13985 R2: 0.31970\n",
      "claimant_embeddings_context & claimant_category & publisher_category____________ MSE: 1.14100 R2: 0.31901\n",
      "claimant_embeddings_context & publisher_category________________________________ MSE: 1.14151 R2: 0.31870\n",
      "claimant_embeddings_context & claimant_category & publisher & publisher_category MSE: 1.14379 R2: 0.31735\n",
      "claimant_embeddings_context & publisher & publisher_category____________________ MSE: 1.14427 R2: 0.31706\n",
      "claimant_embeddings_context & publisher_________________________________________ MSE: 1.14436 R2: 0.31700\n",
      "claimant_embeddings_context & claimant_category & publisher_____________________ MSE: 1.14442 R2: 0.31697\n",
      "claimant_category & publisher___________________________________________________ MSE: 1.32854 R2: 0.20708\n",
      "claimant_category & publisher & publisher_category______________________________ MSE: 1.33066 R2: 0.20581\n",
      "publisher_______________________________________________________________________ MSE: 1.38974 R2: 0.17055\n",
      "publisher & publisher_category__________________________________________________ MSE: 1.39188 R2: 0.16927\n",
      "claimant_category & publisher_category__________________________________________ MSE: 1.50091 R2: 0.10420\n",
      "claimant_category_______________________________________________________________ MSE: 1.57172 R2: 0.06194\n",
      "publisher_category______________________________________________________________ MSE: 1.62475 R2: 0.03029\n"
     ]
    }
   ],
   "source": [
    "# run linear regression model\n",
    "model = LinearRegression()\n",
    "results = {}\n",
    "for feature_combination in tqdm(feature_combinations, desc='Running Linear Regression experiments'):\n",
    "    mse, r2 = run_experiment(train_split, test_split, binarizers, feature_combination, model)\n",
    "    results[feature_combination] = (mse, r2)\n",
    "\n",
    "# print results in order of best performing\n",
    "for combination, (mse, r2) in  sorted(results.items(), key=lambda x: x[1]):\n",
    "    print(f'{\" & \".join(combination):_<80} MSE: {mse:.5f} R2: {r2:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f19e74263141eb81d9eea7b6243d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running LinearSVR experiments:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claimant_embeddings & claimant_category & publisher_____________________________ MSE: 1.09784 R2: 0.34477\n",
      "claimant_embeddings & publisher & publisher_category____________________________ MSE: 1.09960 R2: 0.34372\n",
      "claimant_embeddings & claimant_category & publisher & publisher_category________ MSE: 1.09971 R2: 0.34365\n",
      "claimant_embeddings & publisher_________________________________________________ MSE: 1.10551 R2: 0.34019\n",
      "claimant_embeddings & publisher_category________________________________________ MSE: 1.11756 R2: 0.33300\n",
      "claimant_embeddings & claimant_category & publisher_category____________________ MSE: 1.11896 R2: 0.33216\n",
      "claimant_embeddings_context & publisher_________________________________________ MSE: 1.12416 R2: 0.32906\n",
      "claimant_embeddings_context & claimant_category & publisher_____________________ MSE: 1.12506 R2: 0.32852\n",
      "claimant_embeddings_context & publisher & publisher_category____________________ MSE: 1.12529 R2: 0.32838\n",
      "claimant_embeddings_context & claimant_category & publisher & publisher_category MSE: 1.12664 R2: 0.32758\n",
      "claimant_embeddings_context & claimant_category & publisher_category____________ MSE: 1.12765 R2: 0.32698\n",
      "claimant_embeddings_context & publisher_category________________________________ MSE: 1.12872 R2: 0.32634\n",
      "claimant_embeddings_context & claimant_category_________________________________ MSE: 1.12946 R2: 0.32589\n",
      "claimant_embeddings & claimant_category_________________________________________ MSE: 1.13244 R2: 0.32412\n",
      "claimant_embeddings_context_____________________________________________________ MSE: 1.13249 R2: 0.32409\n",
      "claimant_embeddings_____________________________________________________________ MSE: 1.13860 R2: 0.32044\n",
      "claimant_category & publisher & publisher_category______________________________ MSE: 1.32791 R2: 0.20745\n",
      "claimant_category & publisher___________________________________________________ MSE: 1.32792 R2: 0.20745\n",
      "publisher & publisher_category__________________________________________________ MSE: 1.38928 R2: 0.17083\n",
      "publisher_______________________________________________________________________ MSE: 1.38947 R2: 0.17071\n",
      "claimant_category & publisher_category__________________________________________ MSE: 1.50074 R2: 0.10430\n",
      "claimant_category_______________________________________________________________ MSE: 1.57191 R2: 0.06183\n",
      "publisher_category______________________________________________________________ MSE: 1.62371 R2: 0.03091\n"
     ]
    }
   ],
   "source": [
    "# run more robust LinearSVR model\n",
    "model = LinearSVR(dual=False, loss='squared_epsilon_insensitive')\n",
    "results = {}\n",
    "for feature_combination in tqdm(feature_combinations, desc='Running LinearSVR experiments'):\n",
    "    mse, r2 = run_experiment(train_split, test_split, binarizers, feature_combination, model)\n",
    "    results[feature_combination] = (mse, r2)\n",
    "\n",
    "# print results in order of best performing\n",
    "for combination, (mse, r2) in  sorted(results.items(), key=lambda x: x[1]):\n",
    "    print(f'{\" & \".join(combination):_<80} MSE: {mse:.5f} R2: {r2:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
